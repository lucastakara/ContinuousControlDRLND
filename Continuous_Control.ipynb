{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous Control\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the second project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893) program.\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing the necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Reacher.app\"`\n",
    "- **Windows** (x86): `\"path/to/Reacher_Windows_x86/Reacher.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Reacher_Windows_x86_64/Reacher.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Reacher_Linux/Reacher.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Reacher_Linux/Reacher.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Reacher_Linux_NoVis/Reacher.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Reacher.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Reacher.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\tgoal_speed -> 1.0\n",
      "\t\tgoal_size -> 5.0\n",
      "Unity brain name: ReacherBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 33\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=r'C:\\Users\\Lucas-PC\\Downloads\\Reacher_Windows_x86_64\\Reacher.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "In this environment, a double-jointed arm can move to target locations. A reward of `+0.1` is provided for each step that the agent's hand is in the goal location. Thus, the goal of your agent is to maintain its position at the target location for as many time steps as possible.\n",
    "\n",
    "The observation space consists of `33` variables corresponding to position, rotation, velocity, and angular velocities of the arm.  Each action is a vector with four numbers, corresponding to torque applicable to two joints.  Every entry in the action vector must be a number between `-1` and `1`.\n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 20\n",
      "Size of each action: 4\n",
      "There are 20 agents. Each observes a state with length: 33\n",
      "The state for the first agent looks like: [ 0.00000000e+00 -4.00000000e+00  0.00000000e+00  1.00000000e+00\n",
      " -0.00000000e+00 -0.00000000e+00 -4.37113883e-08  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00 -1.00000000e+01  0.00000000e+00\n",
      "  1.00000000e+00 -0.00000000e+00 -0.00000000e+00 -4.37113883e-08\n",
      "  0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "  0.00000000e+00  0.00000000e+00  5.75471878e+00 -1.00000000e+00\n",
      "  5.55726624e+00  0.00000000e+00  1.00000000e+00  0.00000000e+00\n",
      " -1.68164849e-01]\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total score (averaged over agents) this episode: 0.3199999928474426\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name]     # reset the environment    \n",
    "states = env_info.vector_observations                  # get the current state (for each agent)\n",
    "scores = np.zeros(num_agents)                          # initialize the score (for each agent)\n",
    "while True:\n",
    "    actions = np.random.randn(num_agents, action_size) # select an action (for each agent)\n",
    "    actions = np.clip(actions, -1, 1)                  # all actions between -1 and 1\n",
    "    env_info = env.step(actions)[brain_name]           # send all actions to tne environment\n",
    "    next_states = env_info.vector_observations         # get next state (for each agent)\n",
    "    rewards = env_info.rewards                         # get reward (for each agent)\n",
    "    dones = env_info.local_done                        # see if episode finished\n",
    "    scores += env_info.rewards                         # update the score (for each agent)\n",
    "    states = next_states                               # roll over states to next time step\n",
    "    if np.any(dones):                                  # exit loop if episode finished\n",
    "        break\n",
    "print('Total score (averaged over agents) this episode: {}'.format(np.mean(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "def weights_init_lim(layer):\n",
    "    # similar to Xavier initialization except it's\n",
    "    input_dim = layer.weight.data.size()[0] #dimension of the input layer\n",
    "    lim = 1./np.sqrt(input_dim)\n",
    "    return (-lim, lim)\n",
    "\n",
    "class PPO_Actor(nn.Module):\n",
    "    \"\"\"\n",
    "        Actor: input state (array), convert into action. Based on that\n",
    "               action create a prob distribution. Based on that distribution\n",
    "               resample another action. Output the resampled action and prob dist.\n",
    "               Lastly an entropy term is created for exploration.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, device,\n",
    "                 hidden_layer1, hidden_layer2, hidden_layer3, seed=0):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Key Params\n",
    "        ======\n",
    "        inputs:\n",
    "            state_size (int): Dimension of input state\n",
    "            action_size (int): Dimension of out action size\n",
    "            seed (int): Random seed\n",
    "            hidden_layer1(int): number of neurons in first hidden layer\n",
    "            hidden_layer2(int): number of neurons in second hidden layer\n",
    "            hidden_layer3(int): number of neurons in second hidden layer\n",
    "        outputs:\n",
    "            probability distribution (float) range 0:+1 of sampled action\n",
    "            action as recommended by the network range -1:+1\n",
    "            sampled action range -1:+1\n",
    "            entropy for noise\n",
    "        \"\"\"\n",
    "        super(PPO_Actor, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "\n",
    "        # input size: batch_size or num_agents x state_size\n",
    "        self.bn_1a = nn.BatchNorm1d(state_size)\n",
    "        self.fc_1a = nn.Linear(state_size, hidden_layer1)\n",
    "\n",
    "        self.bn_2a = nn.BatchNorm1d(hidden_layer1)\n",
    "        self.fc_2a = nn.Linear(hidden_layer1, hidden_layer2)\n",
    "\n",
    "        self.bn_3a = nn.BatchNorm1d(hidden_layer2)\n",
    "        self.fc_3a = nn.Linear(hidden_layer2, hidden_layer3)\n",
    "\n",
    "        self.bn_4a = nn.BatchNorm1d(hidden_layer3)\n",
    "        self.fc_4a = nn.Linear(hidden_layer3, action_size)\n",
    "\n",
    "        # std of the distribution for the resampled action\n",
    "        self.std = nn.Parameter(torch.ones(1, action_size)*0.15)\n",
    "\n",
    "        self.PReLU = nn.PReLU() # leaky relu\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # initialize the values\n",
    "        self.fc_1a.weight.data.uniform_(*weights_init_lim(self.fc_1a))\n",
    "        self.fc_2a.weight.data.uniform_(*weights_init_lim(self.fc_2a))\n",
    "        self.fc_3a.weight.data.uniform_(*weights_init_lim(self.fc_3a))\n",
    "        self.fc_4a.weight.data.uniform_(-1e-3,1e-3)\n",
    "\n",
    "    def forward(self, s, resampled_action=None, std_scale=1.0):\n",
    "        \"\"\"Build a network that maps state -> actions.\"\"\"\n",
    "        # state, apply batch norm BEFORE activation\n",
    "        s = self.PReLU(self.fc_1a(self.bn_1a(s))) #linear -> batchnorm -> activation\n",
    "        s = self.PReLU(self.fc_2a(self.bn_2a(s)))\n",
    "        s = self.PReLU(self.fc_3a(self.bn_3a(s)))\n",
    "        action_mean = torch.tanh(self.fc_4a(self.bn_4a(s))) #-> action/critic streams\n",
    "\n",
    "        # action_mean: proposed action, we will then use this action as\n",
    "        # mean to generate a prob distribution to output log_prob\n",
    "        # base on the action as mean create a distribution with zero std...\n",
    "        # dist = torch.distributions.Normal(a_mean, F.softplus(self.std))\n",
    "        dist = torch.distributions.Normal(action_mean, F.hardtanh(self.std,\n",
    "                                                                  min_val=0.05*std_scale,\n",
    "                                                                  max_val=0.5*std_scale))\n",
    "        # sample from the prob distribution just generated again\n",
    "        if resampled_action is None:\n",
    "            resampled_action = dist.sample() #num_agent/batch_size x action_size\n",
    "\n",
    "        # then we have log( p(resampled_action | state) ): batchsize, 1\n",
    "        log_prob = dist.log_prob(resampled_action).sum(-1).unsqueeze(-1)\n",
    "        entropy = dist.entropy().mean() #entropy for noise\n",
    "        # final output\n",
    "        return log_prob, action_mean, resampled_action, entropy\n",
    "\n",
    "\n",
    "class PPO_Critic(nn.Module):\n",
    "    \"\"\"\n",
    "        PPO Critic Network.\n",
    "        Critic: input a state and output a Q value (action is implicit)\n",
    "                The Q value is used to calculate advantage score and td value.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state_size, action_size, device,\n",
    "                 hidden_layer1, hidden_layer2, hidden_layer3, seed=0):\n",
    "        \"\"\"Initialize parameters and build model.\n",
    "        Key Params\n",
    "        ======\n",
    "        inputs:\n",
    "            input_channel (int): Dimension of input state\n",
    "            action_size (int): Dimension of each action\n",
    "            seed (int): Random seed\n",
    "            hidden_layer1(int): number of neurons in first hidden layer\n",
    "            hidden_layer2(int): number of neurons in second hidden layer\n",
    "            hidden_layer3(int): number of neurons in second hidden layer\n",
    "        outputs:\n",
    "            V or Q value estimation (float) real number\n",
    "        \"\"\"\n",
    "\n",
    "        super(PPO_Critic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "\n",
    "        ################# STATE INPUTS ##################\n",
    "        # input size: batch_size or m x state_size\n",
    "        self.bn_1s = nn.BatchNorm1d(state_size)\n",
    "        self.fc_1s = nn.Linear(state_size, hidden_layer1)\n",
    "\n",
    "        ########### ACTION INPUTS / MERGE LAYERS #########\n",
    "        # input size: batch_size or num_agents x action sizes\n",
    "        #self.fc_1m = nn.Linear(hidden_layer1+action_size, hidden_layer2)\n",
    "        self.bn_2s = nn.BatchNorm1d(hidden_layer1)\n",
    "        self.fc_2s = nn.Linear(hidden_layer1, hidden_layer2)\n",
    "\n",
    "        self.bn_3s = nn.BatchNorm1d(hidden_layer2)\n",
    "        self.fc_3s = nn.Linear(hidden_layer2, hidden_layer3)\n",
    "\n",
    "        self.bn_4s = nn.BatchNorm1d(hidden_layer3)\n",
    "        self.fc_4s = nn.Linear(hidden_layer3, 1)\n",
    "\n",
    "        self.PReLU = nn.PReLU() # leaky relu\n",
    "\n",
    "        self.to(device)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        # initialize the values\n",
    "        self.fc_1s.weight.data.uniform_(*weights_init_lim(self.fc_1s))\n",
    "        self.fc_2s.weight.data.uniform_(*weights_init_lim(self.fc_2s))\n",
    "        self.fc_3s.weight.data.uniform_(*weights_init_lim(self.fc_3s))\n",
    "        self.fc_4s.weight.data.uniform_(-1e-3,1e-3)\n",
    "\n",
    "    def forward(self, s, a):\n",
    "        \"\"\"Build a network that maps state -> actions.\"\"\"\n",
    "        # state, apply batch norm BEFORE activation\n",
    "        # state network\n",
    "        s = self.PReLU(self.fc_1s(self.bn_1s(s)))\n",
    "\n",
    "        s = self.PReLU(self.fc_2s(self.bn_2s(s)))\n",
    "\n",
    "        s = self.PReLU(self.fc_3s(self.bn_3s(s)))\n",
    "\n",
    "        # Q value\n",
    "        v = self.PReLU(self.fc_4s(self.bn_4s(s)))\n",
    "\n",
    "        # final output\n",
    "        return v\n",
    "\n",
    "class PPO_ActorCritic(nn.Module):\n",
    "\n",
    "    def __init__(self, state_size, action_size, device, seed=0):\n",
    "\n",
    "        super(PPO_ActorCritic, self).__init__()\n",
    "        self.seed = torch.manual_seed(seed)\n",
    "        self.actor = PPO_Actor(state_size, action_size, device, 1024, 1024, 512, seed=seed)\n",
    "        self.critic = PPO_Critic(state_size, action_size, device, 1024, 1024, 512, seed=seed)\n",
    "\n",
    "\n",
    "    def forward(self, s, action=None, std_scale=1.0):\n",
    "        log_prob, action_mean, resampled_action, entropy = self.actor(s, action,\n",
    "                                                                      std_scale)\n",
    "        if action is None: action = resampled_action\n",
    "        v = self.critic(s, action)\n",
    "\n",
    "        pred = {'log_prob': log_prob, # prob dist based on actions generated, grad true,  (num_agents, 1)\n",
    "                'a': resampled_action, #sampled action based on prob dist torch (num_agents,action_size)\n",
    "                'a_mean': action_mean, #original action as recommended by the network\n",
    "                'ent': entropy, #for noise, grad true, (num_agents or m, 1)\n",
    "                'v': v #Q score, state's V value, grad true (num_agents or m,1)\n",
    "                }\n",
    "        # final output\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.utils as U\n",
    "from collections import namedtuple, deque\n",
    "\n",
    "\n",
    "##### CONFIG PARMAS #####\n",
    "BATCH_SIZE = 1024             # batch size of sampling\n",
    "MIN_BATCH_NO = 32             # min no of batches needed in the memory before learning\n",
    "GAMMA = 0.95                  # discount factor\n",
    "T_MAX = 512                   # max number of time step for collecting trajectory\n",
    "T_MAX_EPS = int(3e4)          # max number of steps before break\n",
    "LR = 1e-4                     # learning rate #5e-4\n",
    "OPTIM_EPSILON = 1e-5          # EPS for Adam optimizer\n",
    "OPTIM_WGT_DECAY =  1e-4       # Weight Decay for Adam optimizer\n",
    "GRAD_CLIP_MAX = 1.0           # max gradient allowed\n",
    "CRITIC_L_WEIGHT = 1.0         # mean square error term weight\n",
    "ENT_WEIGHT = 0.01             # weight of entropy added\n",
    "ENT_DECAY = 0.995             # decay of entropy per 'step'\n",
    "STD_SCALE_INIT = 1.0          # initial value of std scale for action resampling\n",
    "STD_SCALE_DECAY = 0.995       # scale decay of std\n",
    "P_RATIO_EPS = 0.1             # eps for ratio clip 1+eps, 1-eps\n",
    "EPS_DECAY = 0.995             # decay factor for eps for ppo clip\n",
    "NAN_PENALTY = -5.0            # penalty for actions that resulted in nan reward\n",
    "USE_GAE = True                # use GAE flag\n",
    "GAE_TAU = 0.99                # value control how much agent rely on current estimate\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class PPO_Agent():\n",
    "    \"\"\"Interacts with and learns from the environment.\"\"\"\n",
    "\n",
    "    def __init__(self, env, state_size, action_size, num_agents=20, seed=0):\n",
    "        \"\"\"Initialize an Agent object.\n",
    "        Params\n",
    "        ======\n",
    "            env (env object): object of the env\n",
    "            state_size (int): dimension of each state\n",
    "            action_size (int): dimension of each action\n",
    "            num_agents (int): number of agents run in parallel\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.env = env\n",
    "        self.brain_name = self.env.brain_names[0]\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.num_agents = num_agents\n",
    "        self.seed = random.seed(seed)\n",
    "        self.gamma = GAMMA # discount rate\n",
    "        self.t_max = T_MAX # max number of steps for episodic exploration\n",
    "\n",
    "        # Replay memory\n",
    "        self.memory = ReplayBuffer(BATCH_SIZE, num_agents, seed)\n",
    "\n",
    "        # Init Network Models and Optimizers\n",
    "        self.model_local = PPO_ActorCritic(state_size, action_size, device, seed).to(device)\n",
    "        self.optim = optim.Adam(self.model_local.parameters(), lr=LR,\n",
    "                                eps=OPTIM_EPSILON, weight_decay=OPTIM_WGT_DECAY)\n",
    "\n",
    "        # Initialize time step (for updating every UPDATE_EVERY steps and others)\n",
    "        self.t_step = 1\n",
    "\n",
    "        # entropy\n",
    "        self.ent_weight = ENT_WEIGHT\n",
    "        # eps for clipping\n",
    "        self.p_ration_eps = P_RATIO_EPS\n",
    "        # std for noise\n",
    "        self.std_scale = STD_SCALE_INIT\n",
    "\n",
    "        # for tracking\n",
    "        self.total_steps = deque(maxlen=100)\n",
    "        self.episodic_rewards = deque(maxlen=1000) # hist of rewards total of DONE episodes\n",
    "        self.running_rewards = np.zeros(self.num_agents)\n",
    "\n",
    "        self.critic_loss_hist = deque(maxlen=100)\n",
    "        self.actor_gain_hist = deque(maxlen=100)\n",
    "\n",
    "        # training or just accumulating experience?\n",
    "        self.is_training = False\n",
    "\n",
    "        print(\"current device: \", device)\n",
    "\n",
    "\n",
    "    def _toTorch(self, s, dtype=torch.float32):\n",
    "        return torch.tensor(s, dtype=dtype, device=device)\n",
    "\n",
    "    def act(self, state):\n",
    "        \"\"\"Returns deterministic actions for given state using the\n",
    "           Actor policy Network.\n",
    "        Params\n",
    "        ======\n",
    "            state (array_like): current state, # agents x state_space\n",
    "            action_values (array like, -1:+1) no grad\n",
    "        \"\"\"\n",
    "        with torch.no_grad():\n",
    "            _prob, _a_mean, action, _ent = self.model_local.actor(self._toTorch(state),\n",
    "                                                                  std_scale=0.0)\n",
    "\n",
    "        return np.clip(action.detach().cpu().numpy(), -1 , 1)\n",
    "\n",
    "\n",
    "    def _collect_trajectory_data(self, train_mode=True, is_collecting=True):\n",
    "        \"\"\"\n",
    "        Collect trajectory data and store them\n",
    "        output: tuple of list (len: len(states)) of:\n",
    "                states, log_probs, actions, rewards, As, rts\n",
    "        \"\"\"\n",
    "\n",
    "        # reset env and running reward\n",
    "        env_info = self.env.reset(train_mode=train_mode)[self.brain_name] # reset env\n",
    "        self.running_rewards = np.zeros(self.num_agents)\n",
    "\n",
    "        s, p, a, r, ns, d, A, V, rt = ([] for l in range(9)) #initialization\n",
    "\n",
    "        # initial state\n",
    "        state = self._toTorch(env_info.vector_observations) # tensor: num_agents x state_size\n",
    "\n",
    "        # Collect the STEP trajectory data (s,a,r,ns,d)\n",
    "        ep_len = 0\n",
    "        while True:\n",
    "            # state -> prob / actions\n",
    "            state_predict = self.model_local(state, std_scale=self.std_scale)\n",
    "\n",
    "            action = state_predict['a'] #torch, num_agents x action_size no grad\n",
    "            action = np.clip(action.cpu().detach().numpy(), -1., 1.)\n",
    "            if np.any(np.isnan(action)):\n",
    "                print(\"nan action encountered!\")\n",
    "                return\n",
    "\n",
    "            env_info = self.env.step(action)[self.brain_name]\n",
    "\n",
    "            next_state = self._toTorch(env_info.vector_observations)\n",
    "            reward = np.array(env_info.rewards) # array: (num_agents,)\n",
    "            done = np.array(env_info.local_done) #array: (num_agents,) boolean\n",
    "\n",
    "            # recognize the current reward first\n",
    "            if not np.any(np.isnan(reward)):\n",
    "                self.running_rewards += reward\n",
    "            else:\n",
    "                self.running_rewards += NAN_PENALTY\n",
    "                print(\"nan reward encountered!\")\n",
    "            if is_collecting:\n",
    "                s.append(state) #TENSOR: num_agents x state_size (129)\n",
    "                p.append(state_predict['log_prob'].detach()) #tensor: (num_agents x 1), NO grad\n",
    "                a.append(state_predict['a']) #tensor: num_agents x action_size\n",
    "                r.append(np.array(reward).reshape(-1,1)) #array: num_agents x 1\n",
    "                ns.append(next_state) #TENSOR: num_agents x state_size (129)\n",
    "                d.append(1.*np.array(done).reshape(-1,1)) #array: num_agents x 1ï¼Œ 1. 0.\n",
    "                V.append(state_predict['v'].cpu().detach().numpy()) #Q value TENSOR:\n",
    "                                                              #num_agents x 1, require grad\n",
    "            state = next_state\n",
    "\n",
    "            if ep_len >= T_MAX:\n",
    "                if is_collecting:\n",
    "                    is_collecting = False\n",
    "                    last_state = next_state\n",
    "\n",
    "                if np.all(done) or ep_len>=T_MAX_EPS: #only if t_max is reached and np.all done.\n",
    "                    agents_mean_eps_reward = np.nanmean(self.running_rewards+1e-10)\n",
    "                    if not np.isnan(agents_mean_eps_reward):\n",
    "                        self.episodic_rewards.append(agents_mean_eps_reward) #avoid nan\n",
    "                    self.total_steps.append(ep_len)\n",
    "                    break\n",
    "\n",
    "            ep_len += 1\n",
    "\n",
    "        assert(len(s) == T_MAX+1)\n",
    "\n",
    "        # Compute the Advantage/Return value\n",
    "        # note that last state has no entry in record in V\n",
    "        last_state_predict = self.model_local(last_state)\n",
    "\n",
    "        # use td target as return, td error as advantage\n",
    "        V.append(last_state_predict['v'])\n",
    "\n",
    "        advantage = np.zeros([self.num_agents, 1])\n",
    "        returns = last_state_predict['v'].cpu().detach().numpy()\n",
    "        for i in reversed(range(T_MAX)):\n",
    "            # effect of this loop is similar future credit assignments\n",
    "            returns = r[i] + GAMMA * (1-d[i]) * returns\n",
    "            #td_current = V[i].detach().numpy()\n",
    "            if not USE_GAE:\n",
    "                advantage = returns - V[i]\n",
    "            else:\n",
    "                td_error = r[i] + GAMMA * (1-d[i]) * V[i+1] - V[i]\n",
    "                advantage = advantage * GAE_TAU * GAMMA * (1-d[i]) + td_error\n",
    "            A.append(advantage) #array:, num_agents x 1, no grad\n",
    "            rt.append(returns) #array:, num_agents x 1, no grad\n",
    "\n",
    "        # reverse the list order\n",
    "        A = A[::-1]\n",
    "        rt = rt[::-1]\n",
    "\n",
    "        # store data in memory\n",
    "        self.memory.add((s, p, a, r, A, rt)) #tuple of list by types of data\n",
    "\n",
    "\n",
    "    def step(self, train_mode=True):\n",
    "        \"\"\" a step of collecting, sampling data and learn from it\n",
    "            eps: for exploration if external noise is added\n",
    "            train_mode: for the env\n",
    "        \"\"\"\n",
    "\n",
    "        self._collect_trajectory_data(train_mode=train_mode)\n",
    "\n",
    "        if train_mode and len(self.memory) >= BATCH_SIZE * MIN_BATCH_NO:\n",
    "            if self.is_training == False:\n",
    "                print(\"Prefetch completed. Training starts! \\r\")\n",
    "                print(\"Number of Agents: \", self.num_agents)\n",
    "                print(\"Device: \", device)\n",
    "                self.is_training = True\n",
    "\n",
    "            randomized_batches = self.memory.retrieve_memory() #sample from memory\n",
    "            self.learn(randomized_batches) #learn from it and update grad\n",
    "\n",
    "            # entropy weight decay\n",
    "            self.ent_weight *= ENT_DECAY\n",
    "            # std decay\n",
    "            self.std_scale *= STD_SCALE_DECAY\n",
    "            # eps decay\n",
    "            self.p_ration_eps *= EPS_DECAY\n",
    "\n",
    "            self.memory.reset()\n",
    "\n",
    "        self.t_step += 1\n",
    "\n",
    "    def learn(self, randomized_batches):\n",
    "        \"\"\"Update the parameters of the policy based on the data in the sampled\n",
    "           trajectory.\n",
    "        Params\n",
    "        ======\n",
    "        inputs:\n",
    "            m_batch: (tuple) of:\n",
    "                batch of states: (tensor) batch_size or num_agents x state_size\n",
    "                batch of old_probs: (tensor) batch_size or num_agents x 1\n",
    "                batch of actions: (tensor) batch_size or num_agents x state_size\n",
    "                batch of rewards: (tensor) batch_size or num_agents x 1\n",
    "                batch of Advantages: (tensor) batch_size or num_agents x 1\n",
    "                batch of Returns/TDs: (tensor) batch_size or num_agents x 1\n",
    "        \"\"\"\n",
    "        for (s, old_prob, old_actions, r, Advantage, returns_) in randomized_batches:\n",
    "            #s, p, a, r, Advantage, td_target = m_batch\n",
    "\n",
    "            ############################# ACTOR LOSS ##############################\n",
    "            s_predictions = self.model_local(s, old_actions, self.std_scale) #use old s, a to get new prob\n",
    "            new_prob = s_predictions['log_prob'] # num_agents x 1\n",
    "            assert(new_prob.requires_grad == True)\n",
    "            assert(Advantage.requires_grad == False)\n",
    "\n",
    "            ratio = (new_prob - old_prob).exp() # # num_agent or m x 1\n",
    "\n",
    "            G = ratio * Advantage\n",
    "\n",
    "            G_clipped = torch.clamp(ratio, min=1.-P_RATIO_EPS,\n",
    "                                           max=1.+P_RATIO_EPS) * Advantage\n",
    "\n",
    "            G_loss = torch.min(G, G_clipped).mean(0)\n",
    "\n",
    "            actor_loss = -(G_loss + self.ent_weight * s_predictions['ent'].mean())\n",
    "\n",
    "            ############################ CRITIC LOSS ##############################\n",
    "            assert(s_predictions['v'].requires_grad == True) #num_agent or m x 1, requires grad\n",
    "\n",
    "            critic_loss = 0.5 * (returns_ - s_predictions['v']).pow(2).mean()\n",
    "\n",
    "            # TOTAL LOSS\n",
    "            total_loss = actor_loss + CRITIC_L_WEIGHT * critic_loss\n",
    "\n",
    "            self.optim.zero_grad()\n",
    "            total_loss.backward() #retain_graph=True\n",
    "            U.clip_grad_norm_(self.model_local.parameters(), GRAD_CLIP_MAX)\n",
    "            self.optim.step()\n",
    "\n",
    "            self.actor_gain_hist.append(-actor_loss.data.cpu().detach().numpy())\n",
    "            self.critic_loss_hist.append(critic_loss.data.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "class ReplayBuffer:\n",
    "    \"\"\"Fixed-size buffer to store experience tuples.\"\"\"\n",
    "\n",
    "    def __init__(self, batch_size, num_agents, seed=0):\n",
    "        \"\"\"Data Structure to store experience object.\n",
    "        Params\n",
    "        ======\n",
    "            buffer_size (int): maximum size of buffer\n",
    "            batch_size (int): size of each training batch\n",
    "            seed (int): random seed\n",
    "        \"\"\"\n",
    "        self.memory = []\n",
    "        self.batch_size = batch_size\n",
    "        self.num_agents = num_agents\n",
    "\n",
    "        # data structure for storing individual experience\n",
    "        self.data = namedtuple(\"data\", field_names=[\"states\", \"old_probs\",\n",
    "                                                    \"actions\", \"rewards\",\n",
    "                                                    \"As\", \"returns\"])\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "\n",
    "    def add(self, single_traj_data):\n",
    "        \"\"\" Add a new experience to memory.\n",
    "            data: (tuple) states, log_probs, rewards, As, Vs\n",
    "        \"\"\"\n",
    "        (s_, p_, a_, r_, A_, rt_) = single_traj_data #equal lengths\n",
    "\n",
    "        for s, p, a, r, A, rt in zip(s_, p_, a_, r_, A_, rt_): #by time step\n",
    "            i = 0\n",
    "            while i < self.num_agents: #by agent\n",
    "                e = self.data(s[i,:], p[i,:].detach(), a[i,:], r[i], A[i], rt[i])\n",
    "                self.memory.append(e)\n",
    "                i += 1\n",
    "\n",
    "    def retrieve_memory(self):\n",
    "        \"\"\"Retrieve all data in memory in randomized order.\"\"\"\n",
    "        # convert memory structure into giant listS by data type\n",
    "        (all_s, all_p, all_a, all_r, all_A, all_rt) = list(zip(*self.memory))\n",
    "        assert(len(all_s) == len(self.memory))\n",
    "\n",
    "        # so that we can normalized Advantage before sampling\n",
    "        all_A = tuple((all_A - np.nanmean(all_A))/np.std(all_A))\n",
    "\n",
    "        indices = np.arange(len(self.memory))\n",
    "        np.random.shuffle(indices)\n",
    "        indices = [indices[div*self.batch_size: (div+1)*self.batch_size]\n",
    "                   for div in range(len(indices) // self.batch_size + 1)]\n",
    "\n",
    "        result = []\n",
    "        for batch_no, sample_ind in enumerate(indices):\n",
    "            if len(sample_ind) >= self.batch_size / 2:\n",
    "                s_s, s_p, s_a, s_r, s_A, s_rt = ([] for l in range(6))\n",
    "\n",
    "                i = 0\n",
    "                while i < len(sample_ind): #while loop is faster\n",
    "                    s_s.append(all_s[sample_ind[i]]) #@each torch, state_size\n",
    "                    s_p.append(all_p[sample_ind[i]]) #@each torch, 1\n",
    "                    s_a.append(all_a[sample_ind[i]]) #@each array, (action_size,)\n",
    "                    s_r.append(all_r[sample_ind[i]]) #@each array, 1\n",
    "                    s_A.append(all_A[sample_ind[i]]) #@each array, 1\n",
    "                    s_rt.append(all_rt[sample_ind[i]]) #@each array, 1\n",
    "                    i += 1\n",
    "\n",
    "                # change the format to tensor and make sure dims are correct for calculation\n",
    "                s_s = torch.stack(s_s).float().to(device)\n",
    "                s_p = torch.stack(s_p).float().to(device)\n",
    "                s_a = torch.stack(s_a).float().to(device)\n",
    "                s_r = torch.from_numpy(np.vstack(s_r)).float().to(device)\n",
    "                s_A = torch.from_numpy(np.stack(s_A)).float().to(device)\n",
    "                s_rt = torch.from_numpy(np.stack(s_rt)).float().to(device)\n",
    "\n",
    "                result.append((s_s, s_p, s_a, s_r, s_A, s_rt))\n",
    "\n",
    "        return result\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        self.memory = []\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Return the current size of internal memory.\"\"\"\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveTrainedModel(agent, path):\n",
    "    state_dicts = {'actor_model': agent.model_local.actor.state_dict(),\n",
    "                   'critic_model': agent.model_local.critic.state_dict()}\n",
    "    torch.save(state_dicts, path)\n",
    "    \n",
    "def loadTrainedModel(agent, path):\n",
    "    state_dicts = torch.load(path,map_location={'cuda:0': 'cpu'})\n",
    "\n",
    "    agent.model_local.actor.load_state_dict(state_dicts['actor_model'])\n",
    "    agent.model_local.critic.load_state_dict(state_dicts['critic_model'])\n",
    "    \n",
    "    return agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current device:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import PPO_util \n",
    "\n",
    "model_dir = 'C:/Users/Lucas-PC/deep-reinforcement-learning/p2_continuous-control/'\n",
    "model_name = 'unity_continuous_' + str(brain_name) + '_' + str(num_agents) + '_maxscore6' + '_agents.pt'\n",
    "\n",
    "agent = PPO_Agent(env, state_size, action_size, num_agents=num_agents, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching experiences... 30720 Prefetch completed. Training starts! \n",
      "Number of Agents:  20\n",
      "Device:  cuda:0\n",
      "e: 1  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 2  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 3  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 4  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 5  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 6  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 7  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 8  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 9  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 10  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 11  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 12  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.99  steps: 1000\n",
      "e: 13  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.98  steps: 1000\n",
      "e: 14  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.98  steps: 1000\n",
      "e: 15  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.98  steps: 1000\n",
      "e: 16  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.98  steps: 1000\n",
      "e: 17  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.98  steps: 1000\n",
      "e: 18  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.98  steps: 1000\n",
      "e: 19  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.98  steps: 1000\n",
      "e: 20  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.98  steps: 1000\n",
      "e: 21  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.97  steps: 1000\n",
      "e: 22  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.97  steps: 1000\n",
      "e: 23  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.97  steps: 1000\n",
      "e: 24  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.97  steps: 1000\n",
      "e: 25  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.97  steps: 1000\n",
      "e: 26  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.97  steps: 1000\n",
      "e: 27  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.97  steps: 1000\n",
      "e: 28  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.97  steps: 1000\n",
      "e: 29  score: 0.02  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.96  steps: 1000\n",
      "e: 30  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.96  steps: 1000\n",
      "e: 31  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.96  steps: 1000\n",
      "e: 32  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.96  steps: 1000\n",
      "e: 33  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.96  steps: 1000\n",
      "e: 34  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.96  steps: 1000\n",
      "e: 35  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.96  steps: 1000\n",
      "e: 36  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.96  steps: 1000\n",
      "e: 37  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.95  steps: 1000\n",
      "e: 38  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.95  steps: 1000\n",
      "e: 39  score: 0.03  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.95  steps: 1000\n",
      "e: 40  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.95  steps: 1000\n",
      "e: 41  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.95  steps: 1000\n",
      "e: 42  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.95  steps: 1000\n",
      "e: 43  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.95  steps: 1000\n",
      "e: 44  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.95  steps: 1000\n",
      "e: 45  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.94  steps: 1000\n",
      "e: 46  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.94  steps: 1000\n",
      "e: 47  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.94  steps: 1000\n",
      "e: 48  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.94  steps: 1000\n",
      "e: 49  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.94  steps: 1000\n",
      "e: 50  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.94  steps: 1000\n",
      "e: 51  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.94  steps: 1000\n",
      "e: 52  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.94  steps: 1000\n",
      "e: 53  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.93  steps: 1000\n",
      "e: 54  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.93  steps: 1000\n",
      "e: 55  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.93  steps: 1000\n",
      "e: 56  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.93  steps: 1000\n",
      "e: 57  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.93  steps: 1000\n",
      "e: 58  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.93  steps: 1000\n",
      "e: 59  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.93  steps: 1000\n",
      "e: 60  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.93  steps: 1000\n",
      "e: 61  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.92  steps: 1000\n",
      "e: 62  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.92  steps: 1000\n",
      "e: 63  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.92  steps: 1000\n",
      "e: 64  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.92  steps: 1000\n",
      "e: 65  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.92  steps: 1000\n",
      "e: 66  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.92  steps: 1000\n",
      "e: 67  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.92  steps: 1000\n",
      "e: 68  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.92  steps: 1000\n",
      "e: 69  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.91  steps: 1000\n",
      "e: 70  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.91  steps: 1000\n",
      "e: 71  score: 0.04  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.91  steps: 1000\n",
      "e: 72  score: 0.05  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.91  steps: 1000\n",
      "e: 73  score: 0.05  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.91  steps: 1000\n",
      "e: 74  score: 0.05  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.91  steps: 1000\n",
      "e: 75  score: 0.05  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.91  steps: 1000\n",
      "e: 76  score: 0.05  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.91  steps: 1000\n",
      "e: 77  score: 0.05  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 78  score: 0.05  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 79  score: 0.05  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 80  score: 0.05  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 81  score: 0.05  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 82  score: 0.06  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 83  score: 0.06  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 84  score: 0.06  Avg score(100e): 0.03  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 85  score: 0.06  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 86  score: 0.06  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 87  score: 0.06  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 88  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.90  steps: 1000\n",
      "e: 89  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.89  steps: 1000\n",
      "e: 90  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.89  steps: 1000\n",
      "e: 91  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.89  steps: 1000\n",
      "e: 92  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.89  steps: 1000\n",
      "e: 93  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.89  steps: 1000\n",
      "e: 94  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.89  steps: 1000\n",
      "e: 95  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.89  steps: 1000\n",
      "e: 96  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.89  steps: 1000\n",
      "e: 97  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.88  steps: 1000\n",
      "e: 98  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.88  steps: 1000\n",
      "e: 99  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.88  steps: 1000\n",
      "e: 100  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.88  steps: 1000\n",
      "e: 101  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.88  steps: 1000\n",
      "e: 102  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.88  steps: 1000\n",
      "e: 103  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.88  steps: 1000\n",
      "e: 104  score: 0.07  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.88  steps: 1000\n",
      "e: 105  score: 0.08  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.87  steps: 1000\n",
      "e: 106  score: 0.08  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.87  steps: 1000\n",
      "e: 107  score: 0.08  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.87  steps: 1000\n",
      "e: 108  score: 0.08  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.87  steps: 1000\n",
      "e: 109  score: 0.08  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.87  steps: 1000\n",
      "e: 110  score: 0.08  Avg score(100e): 0.04  A(g): -0.01  C(l): 0.00  std: 0.87  steps: 1000\n",
      "e: 111  score: 0.08  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.87  steps: 1000\n",
      "e: 112  score: 0.08  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.87  steps: 1000\n",
      "e: 113  score: 0.08  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 114  score: 0.09  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 115  score: 0.09  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 116  score: 0.09  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 117  score: 0.09  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 118  score: 0.09  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 119  score: 0.09  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 120  score: 0.09  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 121  score: 0.09  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 122  score: 0.10  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 123  score: 0.10  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 124  score: 0.10  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.86  steps: 1000\n",
      "e: 125  score: 0.10  Avg score(100e): 0.05  A(g): -0.01  C(l): 0.00  std: 0.85  steps: 1000\n",
      "e: 126  score: 0.10  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.85  steps: 1000\n",
      "e: 127  score: 0.10  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.85  steps: 1000\n",
      "e: 128  score: 0.10  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.85  steps: 1000\n",
      "e: 129  score: 0.10  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.85  steps: 1000\n",
      "e: 130  score: 0.10  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.85  steps: 1000\n",
      "e: 131  score: 0.10  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.85  steps: 1000\n",
      "e: 132  score: 0.10  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.85  steps: 1000\n",
      "e: 133  score: 0.10  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.84  steps: 1000\n",
      "e: 134  score: 0.11  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.84  steps: 1000\n",
      "e: 135  score: 0.11  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.84  steps: 1000\n",
      "e: 136  score: 0.11  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.84  steps: 1000\n",
      "e: 137  score: 0.11  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.84  steps: 1000\n",
      "e: 138  score: 0.11  Avg score(100e): 0.06  A(g): -0.01  C(l): 0.00  std: 0.84  steps: 1000\n",
      "e: 139  score: 0.11  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.84  steps: 1000\n",
      "e: 140  score: 0.11  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.84  steps: 1000\n",
      "e: 141  score: 0.11  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 142  score: 0.12  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 143  score: 0.12  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 144  score: 0.12  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 145  score: 0.12  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 146  score: 0.12  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 147  score: 0.12  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 148  score: 0.12  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 149  score: 0.12  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 150  score: 0.12  Avg score(100e): 0.07  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 151  score: 0.12  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 152  score: 0.12  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.83  steps: 1000\n",
      "e: 153  score: 0.12  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.82  steps: 1000\n",
      "e: 154  score: 0.12  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.82  steps: 1000\n",
      "e: 155  score: 0.12  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.82  steps: 1000\n",
      "e: 156  score: 0.12  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.82  steps: 1000\n",
      "e: 157  score: 0.12  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.82  steps: 1000\n",
      "e: 158  score: 0.12  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.82  steps: 1000\n",
      "e: 159  score: 0.13  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.82  steps: 1000\n",
      "e: 160  score: 0.13  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.82  steps: 1000\n",
      "e: 161  score: 0.13  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 162  score: 0.13  Avg score(100e): 0.08  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 163  score: 0.13  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 164  score: 0.13  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 165  score: 0.13  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 166  score: 0.13  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 167  score: 0.13  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 168  score: 0.13  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 169  score: 0.13  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 170  score: 0.13  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 171  score: 0.13  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 172  score: 0.14  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.81  steps: 1000\n",
      "e: 173  score: 0.14  Avg score(100e): 0.09  A(g): -0.01  C(l): 0.00  std: 0.80  steps: 1000\n",
      "e: 174  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.80  steps: 1000\n",
      "e: 175  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.80  steps: 1000\n",
      "e: 176  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.80  steps: 1000\n",
      "e: 177  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.80  steps: 1000\n",
      "e: 178  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.80  steps: 1000\n",
      "e: 179  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.80  steps: 1000\n",
      "e: 180  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.80  steps: 1000\n",
      "e: 181  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 182  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 183  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 184  score: 0.14  Avg score(100e): 0.10  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 185  score: 0.14  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 186  score: 0.14  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 187  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 188  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 189  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 190  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 191  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 192  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.79  steps: 1000\n",
      "e: 193  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.78  steps: 1000\n",
      "e: 194  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.78  steps: 1000\n",
      "e: 195  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.78  steps: 1000\n",
      "e: 196  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.78  steps: 1000\n",
      "e: 197  score: 0.15  Avg score(100e): 0.11  A(g): -0.01  C(l): 0.00  std: 0.78  steps: 1000\n",
      "e: 198  score: 0.15  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.78  steps: 1000\n",
      "e: 199  score: 0.15  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.78  steps: 1000\n",
      "e: 200  score: 0.15  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.78  steps: 1000\n",
      "e: 201  score: 0.15  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 202  score: 0.15  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 203  score: 0.15  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 204  score: 0.15  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 205  score: 0.16  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 206  score: 0.16  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 207  score: 0.16  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 208  score: 0.16  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 209  score: 0.16  Avg score(100e): 0.12  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 210  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 211  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 212  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.77  steps: 1000\n",
      "e: 213  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 214  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 215  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 216  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 217  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 218  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 219  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 220  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 221  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 222  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 223  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 224  score: 0.16  Avg score(100e): 0.13  A(g): -0.01  C(l): 0.00  std: 0.76  steps: 1000\n",
      "e: 225  score: 0.16  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.75  steps: 1000\n",
      "e: 226  score: 0.16  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.75  steps: 1000\n",
      "e: 227  score: 0.16  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.75  steps: 1000\n",
      "e: 228  score: 0.16  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.75  steps: 1000\n",
      "e: 229  score: 0.16  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.75  steps: 1000\n",
      "e: 230  score: 0.16  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.75  steps: 1000\n",
      "e: 231  score: 0.16  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.75  steps: 1000\n",
      "e: 232  score: 0.16  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.75  steps: 1000\n",
      "e: 233  score: 0.16  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 234  score: 0.16  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 235  score: 0.17  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 236  score: 0.17  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 237  score: 0.17  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 238  score: 0.17  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 239  score: 0.17  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 240  score: 0.17  Avg score(100e): 0.14  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 241  score: 0.17  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 242  score: 0.17  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 243  score: 0.17  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 244  score: 0.17  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.74  steps: 1000\n",
      "e: 245  score: 0.17  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 246  score: 0.17  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 247  score: 0.17  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 248  score: 0.17  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 249  score: 0.17  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 250  score: 0.17  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 251  score: 0.18  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 252  score: 0.18  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 253  score: 0.18  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 254  score: 0.18  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 255  score: 0.18  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 256  score: 0.18  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.73  steps: 1000\n",
      "e: 257  score: 0.18  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.72  steps: 1000\n",
      "e: 258  score: 0.18  Avg score(100e): 0.15  A(g): -0.01  C(l): 0.00  std: 0.72  steps: 1000\n",
      "e: 259  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.72  steps: 1000\n",
      "e: 260  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.72  steps: 1000\n",
      "e: 261  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.72  steps: 1000\n",
      "e: 262  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.72  steps: 1000\n",
      "e: 263  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.72  steps: 1000\n",
      "e: 264  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.72  steps: 1000\n",
      "e: 265  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 266  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 267  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 268  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 269  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 270  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 271  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 272  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 273  score: 0.18  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 274  score: 0.19  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 275  score: 0.19  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 276  score: 0.19  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.71  steps: 1000\n",
      "e: 277  score: 0.19  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 278  score: 0.19  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 279  score: 0.19  Avg score(100e): 0.16  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 280  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 281  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 282  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 283  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 284  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 285  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 286  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 287  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 288  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.70  steps: 1000\n",
      "e: 289  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 290  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 291  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 292  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 293  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 294  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 295  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 296  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 297  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 298  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 299  score: 0.19  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 300  score: 0.20  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.69  steps: 1000\n",
      "e: 301  score: 0.20  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 302  score: 0.20  Avg score(100e): 0.17  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 303  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 304  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 305  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 306  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 307  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 308  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 309  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 310  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 311  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 312  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.68  steps: 1000\n",
      "e: 313  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 314  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 315  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 316  score: 0.20  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 317  score: 0.21  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 318  score: 0.21  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 319  score: 0.21  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 320  score: 0.21  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 321  score: 0.21  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 322  score: 0.21  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 323  score: 0.21  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 324  score: 0.21  Avg score(100e): 0.18  A(g): -0.01  C(l): 0.00  std: 0.67  steps: 1000\n",
      "e: 325  score: 0.21  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 326  score: 0.21  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 327  score: 0.21  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 328  score: 0.21  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 329  score: 0.21  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 330  score: 0.21  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 331  score: 0.21  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 332  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 333  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 334  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 335  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 336  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.66  steps: 1000\n",
      "e: 337  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 338  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 339  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 340  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 341  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 342  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 343  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 344  score: 0.22  Avg score(100e): 0.19  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 345  score: 0.22  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 346  score: 0.22  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 347  score: 0.22  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 348  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.65  steps: 1000\n",
      "e: 349  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 350  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 351  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 352  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 353  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 354  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 355  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 356  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 357  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 358  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 359  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 360  score: 0.23  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.64  steps: 1000\n",
      "e: 361  score: 0.24  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 362  score: 0.24  Avg score(100e): 0.20  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 363  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 364  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 365  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 366  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 367  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 368  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 369  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 370  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 371  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 372  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.63  steps: 1000\n",
      "e: 373  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 374  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 375  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 376  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 377  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 378  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 379  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 380  score: 0.24  Avg score(100e): 0.21  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 381  score: 0.24  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 382  score: 0.24  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 383  score: 0.24  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 384  score: 0.24  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.62  steps: 1000\n",
      "e: 385  score: 0.24  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 386  score: 0.24  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 387  score: 0.24  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 388  score: 0.24  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 389  score: 0.24  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 390  score: 0.25  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 391  score: 0.25  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 392  score: 0.25  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 393  score: 0.25  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 394  score: 0.25  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 395  score: 0.25  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 396  score: 0.25  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 397  score: 0.25  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 398  score: 0.25  Avg score(100e): 0.22  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 399  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 400  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.61  steps: 1000\n",
      "e: 401  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 402  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 403  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 404  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 405  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 406  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 407  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 408  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 409  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 410  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 411  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 412  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.60  steps: 1000\n",
      "e: 413  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 414  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 415  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 416  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 417  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 418  score: 0.25  Avg score(100e): 0.23  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 419  score: 0.25  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 420  score: 0.25  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 421  score: 0.25  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 422  score: 0.25  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 423  score: 0.25  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 424  score: 0.25  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.59  steps: 1000\n",
      "e: 425  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 426  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 427  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 428  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 429  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 430  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 431  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 432  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 433  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 434  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 435  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 436  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 437  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 438  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 439  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 440  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.58  steps: 1000\n",
      "e: 441  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 442  score: 0.26  Avg score(100e): 0.24  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 443  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 444  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 445  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 446  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 447  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 448  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 449  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 450  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 451  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 452  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.57  steps: 1000\n",
      "e: 453  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 454  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 455  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 456  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 457  score: 0.26  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 458  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 459  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 460  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 461  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 462  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 463  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 464  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 465  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 466  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 467  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 468  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.56  steps: 1000\n",
      "e: 469  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 470  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 471  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 472  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 473  score: 0.27  Avg score(100e): 0.25  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 474  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 475  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 476  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 477  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 478  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 479  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 480  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 481  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 482  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 483  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 484  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.55  steps: 1000\n",
      "e: 485  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 486  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 487  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 488  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 489  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 490  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 491  score: 0.27  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 492  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 493  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 494  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 495  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 496  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.54  steps: 1000\n",
      "e: 497  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 498  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 499  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 500  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 501  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 502  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 503  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 504  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 505  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 506  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 507  score: 0.28  Avg score(100e): 0.26  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 508  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 509  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 510  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 511  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 512  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.53  steps: 1000\n",
      "e: 513  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 514  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 515  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 516  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 517  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 518  score: 0.28  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 519  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 520  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 521  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 522  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 523  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 524  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 525  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 526  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 527  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 528  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.52  steps: 1000\n",
      "e: 529  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 530  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 531  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 532  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 533  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 534  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 535  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 536  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 537  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 538  score: 0.29  Avg score(100e): 0.27  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 539  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 540  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 541  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 542  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 543  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 544  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.51  steps: 1000\n",
      "e: 545  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 546  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 547  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 548  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 549  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 550  score: 0.29  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 551  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 552  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 553  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 554  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 555  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 556  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 557  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 558  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 559  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 560  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.50  steps: 1000\n",
      "e: 561  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 562  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 563  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 564  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 565  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 566  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 567  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 568  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 569  score: 0.30  Avg score(100e): 0.28  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 570  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 571  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 572  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 573  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 574  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 575  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 576  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.49  steps: 1000\n",
      "e: 577  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 578  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 579  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 580  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 581  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 582  score: 0.30  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 583  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 584  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 585  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 586  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 587  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 588  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 589  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 590  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 591  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 592  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.48  steps: 1000\n",
      "e: 593  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 594  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 595  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 596  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 597  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 598  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 599  score: 0.31  Avg score(100e): 0.29  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 600  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 601  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 602  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 603  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 604  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 605  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 606  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 607  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 608  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.47  steps: 1000\n",
      "e: 609  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 610  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 611  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 612  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 613  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 614  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 615  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 616  score: 0.31  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 617  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 618  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 619  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 620  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 621  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 622  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 623  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 624  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 625  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 626  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 627  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 628  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.46  steps: 1000\n",
      "e: 629  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 630  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 631  score: 0.32  Avg score(100e): 0.30  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 632  score: 0.32  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 633  score: 0.32  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 634  score: 0.32  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 635  score: 0.32  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 636  score: 0.32  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 637  score: 0.32  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 638  score: 0.32  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 639  score: 0.32  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 640  score: 0.32  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 641  score: 0.32  Avg score(100e): 0.31  A(g): -0.00  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 642  score: 0.32  Avg score(100e): 0.31  A(g): -0.00  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 643  score: 0.32  Avg score(100e): 0.31  A(g): -0.00  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 644  score: 0.32  Avg score(100e): 0.31  A(g): -0.00  C(l): 0.00  std: 0.45  steps: 1000\n",
      "e: 645  score: 0.32  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 646  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 647  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 648  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 649  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 650  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 651  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 652  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 653  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 654  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 655  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 656  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 657  score: 0.33  Avg score(100e): 0.31  A(g): -0.00  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 658  score: 0.33  Avg score(100e): 0.31  A(g): -0.00  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 659  score: 0.33  Avg score(100e): 0.31  A(g): -0.00  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 660  score: 0.33  Avg score(100e): 0.31  A(g): -0.00  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 661  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 662  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 663  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 664  score: 0.33  Avg score(100e): 0.31  A(g): -0.01  C(l): 0.00  std: 0.44  steps: 1000\n",
      "e: 665  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 666  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 667  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 668  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 669  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 670  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 671  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 672  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 673  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 674  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 675  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 676  score: 0.33  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 677  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 678  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 679  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 680  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.43  steps: 1000\n",
      "e: 681  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 682  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 683  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 684  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 685  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 686  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 687  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 688  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 689  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 690  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 691  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 692  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 693  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 694  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 695  score: 0.34  Avg score(100e): 0.32  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 696  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 697  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 698  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 699  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 700  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.42  steps: 1000\n",
      "e: 701  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 702  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 703  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 704  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 705  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 706  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 707  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 708  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 709  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 710  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 711  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 712  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 713  score: 0.34  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 714  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 715  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 716  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 717  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 718  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 719  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 720  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.41  steps: 1000\n",
      "e: 721  score: 0.35  Avg score(100e): 0.33  A(g): -0.00  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 722  score: 0.35  Avg score(100e): 0.33  A(g): -0.00  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 723  score: 0.35  Avg score(100e): 0.33  A(g): -0.00  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 724  score: 0.35  Avg score(100e): 0.33  A(g): -0.00  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 725  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 726  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 727  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 728  score: 0.35  Avg score(100e): 0.33  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 729  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 730  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 731  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 732  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 733  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 734  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 735  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 736  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 737  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 738  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 739  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 740  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.40  steps: 1000\n",
      "e: 741  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 742  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 743  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 744  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 745  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 746  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 747  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 748  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 749  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 750  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 751  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 752  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 753  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 754  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 755  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 756  score: 0.35  Avg score(100e): 0.34  A(g): -0.01  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 757  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 758  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 759  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 760  score: 0.35  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.39  steps: 1000\n",
      "e: 761  score: 0.36  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 762  score: 0.36  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 763  score: 0.36  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 764  score: 0.36  Avg score(100e): 0.34  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 765  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 766  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 767  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 768  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 769  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 770  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 771  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 772  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 773  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 774  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 775  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 776  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 777  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 778  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 779  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 780  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.38  steps: 1000\n",
      "e: 781  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 782  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 783  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 784  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 785  score: 0.36  Avg score(100e): 0.35  A(g): -0.01  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 786  score: 0.36  Avg score(100e): 0.35  A(g): -0.01  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 787  score: 0.36  Avg score(100e): 0.35  A(g): -0.01  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 788  score: 0.36  Avg score(100e): 0.35  A(g): -0.01  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 789  score: 0.36  Avg score(100e): 0.35  A(g): -0.01  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 790  score: 0.36  Avg score(100e): 0.35  A(g): -0.01  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 791  score: 0.36  Avg score(100e): 0.35  A(g): -0.01  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 792  score: 0.36  Avg score(100e): 0.35  A(g): -0.01  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 793  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 794  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 795  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 796  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 797  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 798  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 799  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 800  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 801  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 802  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 803  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 804  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.37  steps: 1000\n",
      "e: 805  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 806  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 807  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 808  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 809  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 810  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 811  score: 0.36  Avg score(100e): 0.35  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 812  score: 0.36  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 813  score: 0.36  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 814  score: 0.36  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 815  score: 0.36  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 816  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 817  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 818  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 819  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 820  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 821  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 822  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 823  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 824  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.36  steps: 1000\n",
      "e: 825  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 826  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 827  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 828  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 829  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 830  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 831  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 832  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 833  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 834  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 835  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 836  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 837  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 838  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 839  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 840  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 841  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 842  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 843  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 844  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 845  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 846  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 847  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 848  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.35  steps: 1000\n",
      "e: 849  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 850  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 851  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 852  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 853  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 854  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 855  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 856  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 857  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 858  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 859  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 860  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 861  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 862  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 863  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 864  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 865  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 866  score: 0.37  Avg score(100e): 0.36  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 867  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 868  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 869  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 870  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 871  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 872  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.34  steps: 1000\n",
      "e: 873  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 874  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 875  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 876  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 877  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 878  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 879  score: 0.37  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 880  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 881  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 882  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 883  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 884  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 885  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 886  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 887  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 888  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 889  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 890  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 891  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 892  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 893  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 894  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 895  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 896  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.33  steps: 1000\n",
      "e: 897  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 898  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 899  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 900  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 901  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 902  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 903  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 904  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 905  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 906  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 907  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 908  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 909  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 910  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 911  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 912  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 913  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 914  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 915  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 916  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 917  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 918  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 919  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 920  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.32  steps: 1000\n",
      "e: 921  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 922  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 923  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 924  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 925  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 926  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 927  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 928  score: 0.38  Avg score(100e): 0.37  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 929  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 930  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 931  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 932  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 933  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 934  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 935  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 936  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 937  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 938  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 939  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 940  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 941  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 942  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 943  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 944  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.31  steps: 1000\n",
      "e: 945  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 946  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 947  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 948  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 949  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 950  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 951  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 952  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 953  score: 0.38  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 954  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 955  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 956  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 957  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 958  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 959  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 960  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 961  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 962  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 963  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 964  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 965  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 966  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 967  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 968  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 969  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 970  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 971  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 972  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.30  steps: 1000\n",
      "e: 973  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 974  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 975  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 976  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 977  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 978  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 979  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 980  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 981  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 982  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 983  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 984  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 985  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 986  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 987  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 988  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 989  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 990  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 991  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 992  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 993  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 994  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 995  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 996  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 997  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 998  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 999  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n",
      "e: 1000  score: 0.39  Avg score(100e): 0.38  A(g): -0.00  C(l): 0.00  std: 0.29  steps: 1000\n"
     ]
    }
   ],
   "source": [
    "episode_max = 1000 # training loop max iterations\n",
    "episode_reward = 0.0\n",
    "mean_rewards = []\n",
    "max_score = -np.inf\n",
    "e = 0\n",
    "goal_reached = False\n",
    "\n",
    "while e < episode_max:\n",
    "\n",
    "    # collect trajectories\n",
    "    agent.step()\n",
    "    episode_reward = agent.episodic_rewards\n",
    "\n",
    "    # display some progress every 20 iterations\n",
    "    if agent.is_training:\n",
    "\n",
    "        # get the average reward of the parallel environments\n",
    "        mean_rewards.append(np.mean(episode_reward))        \n",
    "        \n",
    "        if (e+5)%1==0 :\n",
    "            print(\"e: {}  score: {:.2f}  Avg score(100e): {:.2f}  \"\n",
    "                  \"A(g): {:.2f}  C(l): {:.2f}  std: {:.2f}  steps: {}\".format(e+1, np.mean(episode_reward),\n",
    "                                                                              np.mean(mean_rewards[-100:]),\n",
    "                                                                              np.mean(agent.actor_gain_hist), \n",
    "                                                                              np.mean(agent.critic_loss_hist),\n",
    "                                                                              agent.std_scale, \n",
    "                                                                              int(np.mean(agent.total_steps))))\n",
    "        if np.mean(mean_rewards[-100:]) > max_score:\n",
    "            max_score = np.mean(mean_rewards[-100:])\n",
    "            saveTrainedModel(agent, model_dir + model_name)\n",
    "            \n",
    "        if np.mean(episode_reward) >= 30 and not goal_reached :\n",
    "            goal_reached = True\n",
    "            episode_max = e + 5\n",
    "            print(\"Score reached benchmark of 2000. Problem Solved!\")\n",
    "        \n",
    "        e += 1\n",
    "    else:\n",
    "        print('\\rFetching experiences... {} '.format(len(agent.memory.memory)), end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DDPG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from agent import Agent\n",
    "import torch\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1\tScore: 0.56\tAverage Score: 0.56.10\n",
      "Episode 2\tScore: 1.51\tAverage Score: 1.04.73\n",
      "Episode 3\tScore: 2.23\tAverage Score: 1.43.67\n",
      "Episode 4\tScore: 4.24\tAverage Score: 2.14.18\n",
      "Episode 5\tScore: 6.53\tAverage Score: 3.01.78\n",
      "Episode 6\tScore: 8.62\tAverage Score: 3.951.29\n",
      "Episode 7\tScore: 11.20\tAverage Score: 4.984.02\n",
      "Episode 8\tScore: 12.60\tAverage Score: 5.948.30\n",
      "Episode 9\tScore: 15.34\tAverage Score: 6.9822.82\n",
      "Episode 10\tScore: 21.16\tAverage Score: 8.403.61\n",
      "Episode 11\tScore: 23.47\tAverage Score: 9.777.29\n",
      "Episode 12\tScore: 25.68\tAverage Score: 11.09.17\n",
      "Episode 13\tScore: 29.05\tAverage Score: 12.48.84\n",
      "Episode 14\tScore: 30.78\tAverage Score: 13.78.93\n",
      "Episode 15\tScore: 34.56\tAverage Score: 15.17.00\n",
      "Episode 16\tScore: 36.58\tAverage Score: 16.51.33\n",
      "Episode 17\tScore: 37.49\tAverage Score: 17.74.39\n",
      "Episode 18\tScore: 38.41\tAverage Score: 18.89.38\n",
      "Episode 19\tScore: 38.73\tAverage Score: 19.93.49\n",
      "Episode 20\tScore: 38.66\tAverage Score: 20.87.45\n",
      "Episode 21\tScore: 39.03\tAverage Score: 21.73.47\n",
      "Episode 22\tScore: 38.81\tAverage Score: 22.51.52\n",
      "Episode 23\tScore: 38.92\tAverage Score: 23.22.55\n",
      "Episode 24\tScore: 38.88\tAverage Score: 23.88.62\n",
      "Episode 25\tScore: 38.86\tAverage Score: 24.48.59\n",
      "Episode 26\tScore: 39.00\tAverage Score: 25.03.55\n",
      "Episode 27\tScore: 39.06\tAverage Score: 25.55.52\n",
      "Episode 28\tScore: 38.76\tAverage Score: 26.03.47\n",
      "Episode 29\tScore: 39.22\tAverage Score: 26.48.59\n",
      "Episode 30\tScore: 38.91\tAverage Score: 26.90.66\n",
      "Episode 31\tScore: 39.24\tAverage Score: 27.29.66\n",
      "Episode 32\tScore: 39.07\tAverage Score: 27.66.56\n",
      "Episode 33\tScore: 39.28\tAverage Score: 28.01.56\n",
      "Episode 34\tScore: 39.01\tAverage Score: 28.34.51\n",
      "Episode 35\tScore: 39.04\tAverage Score: 28.64.58\n",
      "Episode 36\tScore: 39.13\tAverage Score: 28.93.58\n",
      "Episode 37\tScore: 39.17\tAverage Score: 29.21.55\n",
      "Episode 38\tScore: 39.18\tAverage Score: 29.47.55\n",
      "Episode 39\tScore: 39.07\tAverage Score: 29.72.55\n",
      "Episode 40\tScore: 39.16\tAverage Score: 29.96.52\n",
      "Episode 41\tScore: 39.25\tAverage Score: 30.18.57\n",
      "\n",
      "Environment solved in 41 episodes!\tAverage Score: 30.18\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def ddpg(n_episodes=300, max_t=1000):\n",
    "    \"\"\" Deep Deterministic Policy Gradients\n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "    \"\"\"\n",
    "    scores_window = deque(maxlen=100)\n",
    "    scores = np.zeros(num_agents)\n",
    "    scores_episode = []\n",
    "    \n",
    "    agents =[] \n",
    "    \n",
    "    for i in range(num_agents):\n",
    "        agents.append(Agent(state_size, action_size, random_seed=0))\n",
    "    \n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        states = env_info.vector_observations\n",
    "        \n",
    "        for agent in agents:\n",
    "            agent.reset()\n",
    "            \n",
    "        scores = np.zeros(num_agents)\n",
    "            \n",
    "        for t in range(max_t):\n",
    "            #actions = [agents[i].act(states[i]) for i in range(num_agents)]\n",
    "            actions = np.array([agents[i].act(states[i]) for i in range(num_agents)])\n",
    "#             if t == 0:\n",
    "#                 print(\"actions\", actions)\n",
    "            env_info = env.step(actions)[brain_name]        # send the action to the environment\n",
    "            next_states = env_info.vector_observations     # get the next state\n",
    "            rewards = env_info.rewards                     # get the reward\n",
    "            dones = env_info.local_done        \n",
    "            \n",
    "            for i in range(num_agents):\n",
    "                agents[i].step(t,states[i], actions[i], rewards[i], next_states[i], dones[i]) \n",
    " \n",
    "            states = next_states\n",
    "            scores += rewards\n",
    "            if t % 20:\n",
    "                print('\\rTimestep {}\\tScore: {:.2f}\\tmin: {:.2f}\\tmax: {:.2f}'\n",
    "                      .format(t, np.mean(scores), np.min(scores), np.max(scores)), end=\"\") \n",
    "            if np.any(dones):\n",
    "                break \n",
    "        score = np.mean(scores)\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores_episode.append(score)\n",
    "\n",
    "        print('\\rEpisode {}\\tScore: {:.2f}\\tAverage Score: {:.2f}'.format(i_episode, score, np.mean(scores_window)), end=\"\\n\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=30.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "            torch.save(Agent.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(Agent.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break\n",
    "            \n",
    "    return scores_episode\n",
    "\n",
    "scores = ddpg()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
